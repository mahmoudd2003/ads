# ---------------- PATH FIX (robust) ----------------
import sys
from pathlib import Path

APP_DIR = Path(__file__).resolve().parent
CANDIDATE_PATHS = [
    APP_DIR,                      # â€¦/ads/
    APP_DIR / "src",             # â€¦/ads/src
    APP_DIR.parent,              # â€¦/
    APP_DIR.parent / "src",      # â€¦/src
]

for p in CANDIDATE_PATHS:
    if p.exists():
        sp = str(p)
        if sp not in sys.path:
            sys.path.insert(0, sp)

# ------------- Imports (after fixing path) -------------
import streamlit as st
import pandas as pd

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø£ÙˆÙ„Ù‰ Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…Ø¹ ØªØ´Ø®ÙŠØµ Ø¥Ø°Ø§ ÙØ´Ù„
try:
    from src.collectors.meta_ads import fetch_ads_by_keywords
    from src.collectors.trends import fetch_trends_scores
    from src.collectors.tiktok_ads import fetch_tiktok_ads
    from src.processing.normalize import normalize_ads
    from src.ai.llm_analyzer import analyze_batches
    from src.processing.scoring import score_gap
except ModuleNotFoundError as e:
    st.error(
        "âŒ Ù„Ù… Ø£Ø³ØªØ·Ø¹ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø­Ø²Ù…Ø© `src`. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…Ø¬Ù„Ø¯ `src/` Ù…ÙˆØ¬ÙˆØ¯ "
        "Ø¥Ù…Ù‘Ø§ Ø¨Ø¬Ø§Ù†Ø¨ `app.py` Ø£Ùˆ ÙÙŠ Ø¬Ø°Ø± Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹. Ø£ÙŠØ¶Ù‹Ø§ ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª "
        "`__init__.py` Ø¯Ø§Ø®Ù„ `src/` ÙˆØ¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯Ø§ØªÙ‡ Ø§Ù„ÙØ±Ø¹ÙŠØ© (`collectors/`, `processing/`, `ai/`)."
    )
    # ØªØ´Ø®ÙŠØµ Ø³Ø±ÙŠØ¹: Ø¹Ø±Ø¶ Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù‚Ø±ÙŠØ¨Ø©
    st.write("ğŸ” Ù…Ø³Ø§Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚:", str(APP_DIR))
    st.write("ğŸ“ Ù…ÙˆØ¬ÙˆØ¯ØŸ ads/src:", (APP_DIR / "src").exists())
    st.write("ğŸ“ Ù…ÙˆØ¬ÙˆØ¯ØŸ ../src :", (APP_DIR.parent / "src").exists())
    st.stop()

# ---------------- Streamlit UI ----------------
st.set_page_config(page_title="Gap Analysis MVP", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š Gap Analysis â€“ MVP (Meta + Google Trends + TikTok)")

with st.sidebar:
    country = st.selectbox("Country", ["JO", "SA", "AE", "EG"], index=0)
    sector = st.selectbox("Sector", ["Furniture", "Electronics", "Fashion", "Food"])
    seeds = st.text_area(
        "Seed keywords (one per line)",
        value="ÙƒÙ†Ø¨\nØ³Ø±ÙŠØ± Ù…Ø¹ ØªØ®Ø²ÙŠÙ†\nÙ…Ø±Ø§ØªØ¨ Ø·Ø¨ÙŠØ©\nØ·Ø§ÙˆÙ„Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø·ÙŠ"
    )
    max_ads = st.slider("Max ads per keyword", 50, 500, 200, 50)
    run = st.button("Run Analysis")

if run:
    kw_list = [s.strip() for s in seeds.splitlines() if s.strip()]

    with st.spinner("Collecting Meta ads..."):
        meta_df = fetch_ads_by_keywords(kw_list, country, limit=max_ads)
    st.success(f"Meta Ads: {len(meta_df)} rows")

    with st.spinner("Collecting Google Trends..."):
        trends_df = fetch_trends_scores(kw_list, country)
    st.success("Trends collected")

    with st.spinner("Collecting TikTok ads (CSV/Apify)..."):
        tiktok_df = fetch_tiktok_ads(kw_list, country)
    st.success(f"TikTok Ads: {len(tiktok_df)} rows")

    with st.spinner("Normalizing..."):
        meta_clean = normalize_ads(meta_df)

    with st.spinner("AI analysis (products/angles/objections)..."):
        llm_df = analyze_batches(meta_clean, country)

    with st.spinner("Scoring gaps..."):
        result = score_gap(meta_clean, llm_df, trends_df, tiktok_df)

    st.subheader("Top Gap Opportunities")
    if result is not None and not result.empty:
        st.dataframe(result.sort_values("gap_score", ascending=False).head(25))
        st.download_button(
            "Download CSV",
            result.to_csv(index=False),
            "gap_opportunities.csv",
            "text/csv"
        )
    else:
        st.info("No results to show yet. Try increasing keywords or ads limit.")
